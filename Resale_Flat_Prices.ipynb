
Resale Flat Prices
# Packages

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")
from datetime import datetime
import plotly as px
import seaborn as sns
import matplotlib.pyplot as plt

#Encoding packages

from sklearn.preprocessing import LabelEncoder,OrdinalEncoder
Reading the "csv" files (Registration)
# reading the 2012 to 2014
df_1= pd.read_csv(r"C:\Users\visithra\Desktop\New folder\ResaleFlatPrices\ResaleFlatPricesBasedonRegistrationDateFromMar2012toDec2014.csv")
df_1.head(2)
month	town	flat_type	block	street_name	storey_range	floor_area_sqm	flat_model	lease_commence_date	resale_price
0	2012-03	ANG MO KIO	2 ROOM	172	ANG MO KIO AVE 4	06 TO 10	45.0	Improved	1986	250000.0
1	2012-03	ANG MO KIO	2 ROOM	510	ANG MO KIO AVE 8	01 TO 05	44.0	Improved	1980	265000.0
# reading the 2015 to 2016
df_2= pd.read_csv(r"C:\Users\visithra\Desktop\New folder\ResaleFlatPrices\ResaleFlatPricesBasedonRegistrationDateFromJan2015toDec2016.csv")
df_2.tail(2)
month	town	flat_type	block	street_name	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price
37151	2016-12	YISHUN	EXECUTIVE	325	YISHUN CTRL	01 TO 03	146.0	Maisonette	1988	70	575000.0
37152	2016-12	YISHUN	MULTI-GENERATION	666	YISHUN AVE 4	10 TO 12	164.0	Multi Generation	1987	70	735000.0
# reading the 2017 to onwards
df_3= pd.read_csv(r"C:\Users\visithra\Desktop\New folder\ResaleFlatPrices\ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv")
df_3.head(2)
month	town	flat_type	block	street_name	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price
0	2017-01	ANG MO KIO	2 ROOM	406	ANG MO KIO AVE 10	10 TO 12	44.0	Improved	1979	61 years 04 months	232000.0
1	2017-01	ANG MO KIO	3 ROOM	108	ANG MO KIO AVE 4	01 TO 03	67.0	New Generation	1978	60 years 07 months	250000.0
Preprocessing
#df_1 does not have a "remaining_lease" column so, I choose the df_2 and df_3 only

#concadinating the df_2 and df_3

df_4= pd.concat([df_2,df_3],axis= 0)
df_4.reset_index(drop= True, inplace= True)
df_4.tail(2)
month	town	flat_type	block	street_name	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price
207821	2024-01	YISHUN	EXECUTIVE	356	YISHUN RING RD	04 TO 06	146.0	Maisonette	1988	63 years 08 months	860000.0
207822	2024-01	YISHUN	EXECUTIVE	606	YISHUN ST 61	04 TO 06	142.0	Apartment	1987	62 years 11 months	795000.0
df_4.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 207823 entries, 0 to 207822
Data columns (total 11 columns):
 #   Column               Non-Null Count   Dtype  
---  ------               --------------   -----  
 0   month                207823 non-null  object 
 1   town                 207823 non-null  object 
 2   flat_type            207823 non-null  object 
 3   block                207823 non-null  object 
 4   street_name          207823 non-null  object 
 5   storey_range         207823 non-null  object 
 6   floor_area_sqm       207823 non-null  float64
 7   flat_model           207823 non-null  object 
 8   lease_commence_date  207823 non-null  int64  
 9   remaining_lease      207823 non-null  object 
 10  resale_price         207823 non-null  float64
dtypes: float64(2), int64(1), object(8)
memory usage: 17.4+ MB
df_4.isnull().sum()
month                  0
town                   0
flat_type              0
block                  0
street_name            0
storey_range           0
floor_area_sqm         0
flat_model             0
lease_commence_date    0
remaining_lease        0
resale_price           0
dtype: int64
# This Dataset have not any null values
Encoding the catogarical columns and
chaning the datatype
df_4.head(2)
month	town	flat_type	block	street_name	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price
0	2015-01	ANG MO KIO	3 ROOM	174	ANG MO KIO AVE 4	07 TO 09	60.0	Improved	1986	70	255000.0
1	2015-01	ANG MO KIO	3 ROOM	541	ANG MO KIO AVE 10	01 TO 03	68.0	New Generation	1981	65	275000.0
# Creating a new column "address"
df_4["address"]= df_4["block"]+" "+df_4["street_name"]
#droping the "street_name" and "block"
df_5= df_4.drop(columns=["block","street_name"])
df_5.head(2)
month	town	flat_type	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price	address
0	2015-01	ANG MO KIO	3 ROOM	07 TO 09	60.0	Improved	1986	70	255000.0	174 ANG MO KIO AVE 4
1	2015-01	ANG MO KIO	3 ROOM	01 TO 03	68.0	New Generation	1981	65	275000.0	541 ANG MO KIO AVE 10
# for month
df_5["month"] = pd.to_datetime(df_5["month"], format="%Y-%m")
#spliting the month column to "Year", "month", "day"
df_5["year"]= df_5["month"].dt.year
df_5["month"]= df_5["month"].dt.month
df_5.head(2)
month	town	flat_type	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price	address	year
0	1	ANG MO KIO	3 ROOM	07 TO 09	60.0	Improved	1986	70	255000.0	174 ANG MO KIO AVE 4	2015
1	1	ANG MO KIO	3 ROOM	01 TO 03	68.0	New Generation	1981	65	275000.0	541 ANG MO KIO AVE 10	2015
df_5["town"].unique()
array(['ANG MO KIO', 'BEDOK', 'BISHAN', 'BUKIT BATOK', 'BUKIT MERAH',
       'BUKIT PANJANG', 'BUKIT TIMAH', 'CENTRAL AREA', 'CHOA CHU KANG',
       'CLEMENTI', 'GEYLANG', 'HOUGANG', 'JURONG EAST', 'JURONG WEST',
       'KALLANG/WHAMPOA', 'MARINE PARADE', 'PASIR RIS', 'PUNGGOL',
       'QUEENSTOWN', 'SEMBAWANG', 'SENGKANG', 'SERANGOON', 'TAMPINES',
       'TOA PAYOH', 'WOODLANDS', 'YISHUN'], dtype=object)
df_5["town"].nunique()
26
df_5["flat_type"].unique()
array(['3 ROOM', '4 ROOM', '5 ROOM', '2 ROOM', 'EXECUTIVE', '1 ROOM',
       'MULTI-GENERATION'], dtype=object)
df_5["flat_type"].nunique()
7
df_5["flat_model"].unique()
array(['Improved', 'New Generation', 'Model A', 'Standard', 'Simplified',
       'Premium Apartment', 'Maisonette', 'Apartment', 'Model A2',
       'Type S1', 'Type S2', 'Adjoined flat', 'Terrace', 'DBSS',
       'Model A-Maisonette', 'Premium Maisonette', 'Multi Generation',
       'Premium Apartment Loft', 'Improved-Maisonette', '2-room', '3Gen'],
      dtype=object)
df_5["flat_model"].nunique()
21
# choosing the "LabelEncoder" for "town",and "OrdinalEncoder" for the "flat_model" and the "flat_type"
df_5["town"]= LabelEncoder().fit_transform(df_5["town"])
df_5["flat_model"]= OrdinalEncoder().fit_transform(df_5[["flat_model"]])
df_5["flat_type"]= OrdinalEncoder().fit_transform(df_5[["flat_type"]])
df_5["town"].unique()
array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19, 20, 21, 22, 23, 24, 25])
df_5["flat_type"].unique()
array([2., 3., 4., 1., 5., 0., 6.])
df_5["flat_model"].unique()
array([ 5., 12.,  8., 17., 16., 13.,  7.,  3., 10., 19., 20.,  2., 18.,
        4.,  9., 15., 11., 14.,  6.,  0.,  1.])
df_5.tail(2)
month	town	flat_type	storey_range	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price	address	year
207821	1	25	5.0	04 TO 06	146.0	7.0	1988	63 years 08 months	860000.0	356 YISHUN RING RD	2024
207822	1	25	5.0	04 TO 06	142.0	3.0	1987	62 years 11 months	795000.0	606 YISHUN ST 61	2024
df_5[["storey_start", "storey_end"]]= df_5["storey_range"].str.split(" TO ",expand=True)
#droping the "storey_range" column
df_5.drop(columns=["storey_range"],inplace= True)
df_5.head(2)
month	town	flat_type	floor_area_sqm	flat_model	lease_commence_date	remaining_lease	resale_price	address	year	storey_start	storey_end
0	1	0	2.0	60.0	5.0	1986	70	255000.0	174 ANG MO KIO AVE 4	2015	07	09
1	1	0	2.0	68.0	12.0	1981	65	275000.0	541 ANG MO KIO AVE 10	2015	01	03
df_5["address"].nunique()
9559
# Address have 9559 unique values in the 207823 , so i encode it for the correlation checking
# I chooshing the "LabelEncoder" for the "address" column

df_5["address"]= LabelEncoder().fit_transform(df_5["address"])
df_5["storey_start"]= df_5["storey_start"].astype(int)
df_5["storey_end"]= df_5["storey_end"].astype(int)
# "remaining_lease" have a "60 years 8 months" this type of data ,
# so we want to split the year and month separately for the correlation checking
slice_values= []
for i in df_5["remaining_lease"].astype(str):
    j= i.replace("years","")
    k= j.replace("months","")
    l= k.replace("month","")
    m= l.strip()
    n= m.split("  ")
    slice_values.append(n)
df_data= pd.DataFrame(slice_values,columns=["remaining_lease_year", "remaining_lease_month"])
df_data["remaining_lease_year"]= df_data["remaining_lease_year"].astype(int)
df_data["remaining_lease_month"]= df_data["remaining_lease_month"].fillna(0).astype(int)
#droping the "remaining_lease" column
df_5.drop(columns=["remaining_lease"],inplace= True)
df_6= pd.concat([df_5,df_data],axis=1)
df_6.columns
Index(['month', 'town', 'flat_type', 'floor_area_sqm', 'flat_model',
       'lease_commence_date', 'resale_price', 'address', 'year',
       'storey_start', 'storey_end', 'remaining_lease_year',
       'remaining_lease_month'],
      dtype='object')
# set the columns
df_7= df_6[['year','month', 'town', 'flat_type', 'floor_area_sqm', 'flat_model', 'address', 
       'storey_start', 'storey_end', 'remaining_lease_year','remaining_lease_month',
       'lease_commence_date', 'resale_price']]
df_8=df_7.sort_values(by=["year","month"])
df_8.to_csv("ResaleFlatPrices.csv", index= False)
# Checking the Correlation using heatmap

df_8_corr= df_8.corr()
plt.figure(figsize=(10,5))
sns.heatmap(df_8_corr,annot= True, cmap="Greens", fmt=".2f")
plt.show()

df_final= pd.read_csv(r"C:\Users\visithra\Desktop\Capstone Projects\ResaleFlatPrices.csv")
df_final.head(2)
year	month	town	flat_type	floor_area_sqm	flat_model	address	storey_start	storey_end	remaining_lease_year	remaining_lease_month	lease_commence_date	resale_price
0	2015	1	0	2.0	60.0	5.0	1632	7	9	70	0	1986	255000.0
1	2015	1	0	2.0	68.0	12.0	6577	1	3	65	0	1981	275000.0
# checking the duplicate values
df_final.duplicated().sum()
305
df_final_1= df_final.drop_duplicates()
df_final_1.reset_index(drop= True, inplace= True)
df_final_1.tail(2)
year	month	town	flat_type	floor_area_sqm	flat_model	address	storey_start	storey_end	remaining_lease_year	remaining_lease_month	lease_commence_date	resale_price
207516	2024	1	25	5.0	146.0	7.0	4457	4	6	63	8	1988	860000.0
207517	2024	1	25	5.0	142.0	3.0	7036	4	6	62	11	1987	795000.0
# The month,address column does have very lowest correlation with other features
# So I drop the month and address columns
df_final_2= df_final_1.drop(columns=["month","address"])
df_final_2.tail(2)
year	town	flat_type	floor_area_sqm	flat_model	storey_start	storey_end	remaining_lease_year	remaining_lease_month	lease_commence_date	resale_price
207516	2024	25	5.0	146.0	7.0	4	6	63	8	1988	860000.0
207517	2024	25	5.0	142.0	3.0	4	6	62	11	1987	795000.0
# detecting the skewed columns using plot
def plot(df,column):
  #distplot
  plt.figure(figsize=(15,4))
  plt.subplot(1,3,1)
  sns.distplot(df[column])
  plt.title("distplot for"+" "+column)

  #histogram plot

  plt.subplot(1,3,2)
  sns.histplot(df, x= column, kde= True, bins=30,color="salmon")
  plt.title("histogram plot for"+" "+column)

  #boxplot

  plt.subplot(1,3,3)

  sns.boxplot(df, x=column)
  plt.title("Box plot for"+" "+column)
for i in df_final_2.columns:
    plot(df_final_2,i)


df_final_2.describe().T
count	mean	std	min	25%	50%	75%	max
year	207518.0	2019.388853	2.559605	2015.0	2017.0	2020.0	2022.0	2024.0
town	207518.0	13.891041	7.958881	0.0	8.0	14.0	21.0	25.0
flat_type	207518.0	3.124293	0.919137	0.0	2.0	3.0	4.0	6.0
floor_area_sqm	207518.0	97.230998	24.062276	31.0	82.0	94.0	112.0	280.0
flat_model	207518.0	8.699597	3.656410	0.0	5.0	8.0	12.0	20.0
storey_start	207518.0	7.659596	5.849433	1.0	4.0	7.0	10.0	49.0
storey_end	207518.0	9.659596	5.849433	3.0	6.0	9.0	12.0	51.0
remaining_lease_year	207518.0	74.153105	13.382287	42.0	63.0	74.0	85.0	97.0
remaining_lease_month	207518.0	4.555349	3.790566	0.0	1.0	4.0	8.0	11.0
lease_commence_date	207518.0	1994.990767	13.585511	1966.0	1984.0	1995.0	2004.0	2022.0
resale_price	207518.0	482057.526272	165997.048100	140000.0	360000.0	450000.0	570000.0	1500000.0
skewness handling
df_final_3= df_final_2.copy()
# The Skewness Columns are
# 2. storey_start
# 3. storey_end
# 4. resale_price
df_final_3["storey_start"]= np.log(df_final_3["storey_start"])
df_final_3["storey_end"]= np.log(df_final_3["storey_end"])
df_final_3["resale_price"]= np.log(df_final_3["resale_price"])
skewed_columns=["storey_start","storey_end","resale_price"]
for i in skewed_columns:
    plot(df_final_3,i)



Outliers Handling - Interquartile Range(IQR) Method
df_final_4= df_final_3.copy()
# The Outlier Columns are
# 1. floor_area_sqm
# 2. storey_start
# 3. sortey_end
# 4. resale_price
# Recorrect the Outliers
# (Ex: lower threshold = 5 and upper threshold = 20)
# above upper threshold values (>20) are converted to upper threshold value (20) in features
# below lower threshold values (<5)  are converted to lower threshold value (5)  in features
def outlier(df,column):
  q1= df[column].quantile(0.25)
  q3= df[column].quantile(0.75)

  iqr= q3-q1

  upper_threshold= q3 + (1.5*iqr)
  lower_threshold= q1 - (1.5*iqr)

  df[column]= df[column].clip(lower_threshold, upper_threshold)
outlier_columns=["floor_area_sqm","storey_start","storey_end","resale_price"]
for j in outlier_columns:
    outlier(df_final_4,j)
for k in outlier_columns:
    plot(df_final_4,k)




# Checking the correlation after the outlier recorrection
plt.figure(figsize=(10,5))
sns.heatmap(df_final_4.corr(), annot= True, cmap="Greens", fmt="0.2f")
plt.show()

Model Selection (Regression)
df_final_5= df_final_4.copy()
df_final_5.describe().T
count	mean	std	min	25%	50%	75%	max
year	207518.0	2019.388853	2.559605	2015.000000	2017.000000	2020.000000	2022.000000	2024.000000
town	207518.0	13.891041	7.958881	0.000000	8.000000	14.000000	21.000000	25.000000
flat_type	207518.0	3.124293	0.919137	0.000000	2.000000	3.000000	4.000000	6.000000
floor_area_sqm	207518.0	97.150330	23.802345	37.000000	82.000000	94.000000	112.000000	157.000000
flat_model	207518.0	8.699597	3.656410	0.000000	5.000000	8.000000	12.000000	20.000000
storey_start	207518.0	1.695671	0.920919	0.011858	1.386294	1.945910	2.302585	3.677021
storey_end	207518.0	2.093418	0.601311	1.098612	1.791759	2.197225	2.484907	3.524627
remaining_lease_year	207518.0	74.153105	13.382287	42.000000	63.000000	74.000000	85.000000	97.000000
remaining_lease_month	207518.0	4.555349	3.790566	0.000000	1.000000	4.000000	8.000000	11.000000
lease_commence_date	207518.0	1994.990767	13.585511	1966.000000	1984.000000	1995.000000	2004.000000	2022.000000
resale_price	207518.0	13.030441	0.329401	12.104561	12.793859	13.017003	13.253392	13.942690
np.exp(13.942690)
1135620.7776035476
#checking how many datas are outliers based on resale_price
df_final_1[df_final_1["resale_price"] >= 1135620]
year	month	town	flat_type	floor_area_sqm	flat_model	address	storey_start	storey_end	remaining_lease_year	remaining_lease_month	lease_commence_date	resale_price
36467	2016	12	14	2.0	259.0	18.0	6800	1	3	54	0	1972	1150000.0
38448	2017	2	2	4.0	120.0	4.0	3216	40	42	93	7	2011	1180000.0
47892	2017	7	18	5.0	156.0	3.0	1224	19	21	77	3	1995	1160000.0
54395	2017	11	7	4.0	107.0	20.0	1937	43	45	92	2	2011	1138000.0
60199	2018	3	7	4.0	107.0	20.0	1934	37	39	91	10	2011	1145000.0
...	...	...	...	...	...	...	...	...	...	...	...	...	...
206356	2024	1	6	5.0	146.0	7.0	6950	7	9	64	7	1989	1300000.0
206360	2024	1	7	4.0	105.0	20.0	1933	46	48	86	1	2011	1450000.0
206460	2024	1	9	4.0	113.0	5.0	3791	34	36	92	8	2017	1240000.0
206745	2024	1	14	3.0	93.0	8.0	327	40	42	93	0	2017	1150000.0
206928	2024	1	18	3.0	97.0	14.0	9252	16	18	91	4	2016	1150000.0
417 rows × 13 columns

np.exp(12.104561)
180694.13157722994
#checking how many datas are outliers based on resale_price
df_final_1[df_final_1["resale_price"] <= 180694]
year	month	town	flat_type	floor_area_sqm	flat_model	address	storey_start	storey_end	remaining_lease_year	remaining_lease_month	lease_commence_date	resale_price
47067	2017	7	4	0.0	31.0	5.0	8055	4	6	56	8	1975	175000.0
62238	2018	4	10	1.0	42.0	17.0	6185	4	6	49	9	1969	180000.0
62989	2018	4	21	2.0	64.0	5.0	3547	13	15	59	2	1978	170000.0
64274	2018	5	15	1.0	42.0	5.0	1411	1	3	55	11	1975	180000.0
65495	2018	6	4	0.0	31.0	5.0	8055	1	3	55	10	1975	176000.0
...	...	...	...	...	...	...	...	...	...	...	...	...	...
120053	2020	11	4	1.0	42.0	17.0	5825	10	12	48	5	1970	180000.0
126747	2021	1	24	1.0	45.0	5.0	2338	7	9	64	5	1986	180000.0
127297	2021	2	4	0.0	31.0	5.0	8055	4	6	53	1	1975	180000.0
197153	2023	8	22	2.0	67.0	8.0	6357	7	9	91	3	2015	150000.0
205731	2023	12	24	1.0	47.0	8.0	1753	28	30	94	11	2019	150000.0
77 rows × 13 columns

# now we want to create the model for "resale_price" prediction
# importing the model
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
import pickle
# Train Test Split for model selection
def select_model(df, algorithm):
    # x, y spliting
    x= df.drop(columns=["resale_price"])
    y= df["resale_price"]

    X_train, X_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=42)

    model= algorithm().fit(X_train,y_train)
    y_pred_train= model.predict(X_train)
    y_pred_test= model.predict(X_test)
    
    #Checking the accuracy score
    train_mse= mean_squared_error(y_train, y_pred_train)
    train_rmse= np.sqrt(train_mse)
    train_mae= mean_absolute_error(y_train, y_pred_train)
    train_r2= r2_score(y_train, y_pred_train)

    test_mse= mean_squared_error(y_test, y_pred_test)
    test_rmse= np.sqrt(test_mse)
    test_mae= mean_absolute_error(y_test, y_pred_test)
    test_r2= r2_score(y_test, y_pred_test)

    metrics_train={"Data": "Train Data",
        "Name":algorithm.__name__,
        "R2_score":train_r2,
        "Mean_squared_error":train_mse,
        "Root_mean_squared_error":train_rmse,
        "Mean_absolute_error":train_mae
        }

    metrics_test={"Data": "Test Data",
           "Name":algorithm.__name__,
           "R2_score":test_r2,
           "Mean_squared_error":test_mse,
           "Root_mean_squared_error":test_rmse,
           "Mean_absolute_error":test_mae
              }

    print(metrics_train)
    print(metrics_test)
    print("")
select_model(df_final_5, LinearRegression)
select_model(df_final_5, DecisionTreeRegressor)
select_model(df_final_5, RandomForestRegressor)
select_model(df_final_5, AdaBoostRegressor)
select_model(df_final_5, ExtraTreesRegressor)
select_model(df_final_5, GradientBoostingRegressor)
select_model(df_final_5, XGBRegressor)
{'Data': 'Train Data', 'Name': 'LinearRegression', 'R2_score': 0.667893944450562, 'Mean_squared_error': 0.036058734035016214, 'Root_mean_squared_error': 0.1898913743038799, 'Mean_absolute_error': 0.14885986246456068}
{'Data': 'Test Data', 'Name': 'LinearRegression', 'R2_score': 0.6670101437509905, 'Mean_squared_error': 0.0360352863965051, 'Root_mean_squared_error': 0.1898296246545968, 'Mean_absolute_error': 0.1490269510529553}

{'Data': 'Train Data', 'Name': 'DecisionTreeRegressor', 'R2_score': 0.9960265302089641, 'Mean_squared_error': 0.00043142329986754215, 'Root_mean_squared_error': 0.020770731808666305, 'Mean_absolute_error': 0.007434562160674587}
{'Data': 'Test Data', 'Name': 'DecisionTreeRegressor', 'R2_score': 0.9263599153645582, 'Mean_squared_error': 0.007969136267372147, 'Root_mean_squared_error': 0.0892700188606015, 'Mean_absolute_error': 0.06400834003299394}

{'Data': 'Train Data', 'Name': 'RandomForestRegressor', 'R2_score': 0.9908582606611736, 'Mean_squared_error': 0.0009925731311668845, 'Root_mean_squared_error': 0.0315051286486325, 'Mean_absolute_error': 0.02242014052524251}
{'Data': 'Test Data', 'Name': 'RandomForestRegressor', 'R2_score': 0.9549115919672535, 'Mean_squared_error': 0.004879348923492424, 'Root_mean_squared_error': 0.0698523365643013, 'Mean_absolute_error': 0.05162172047300155}

{'Data': 'Train Data', 'Name': 'AdaBoostRegressor', 'R2_score': 0.6729425950803551, 'Mean_squared_error': 0.03551057194265614, 'Root_mean_squared_error': 0.18844248974861305, 'Mean_absolute_error': 0.15510940962699268}
{'Data': 'Test Data', 'Name': 'AdaBoostRegressor', 'R2_score': 0.6720532354141493, 'Mean_squared_error': 0.03548953628131283, 'Root_mean_squared_error': 0.18838666694146067, 'Mean_absolute_error': 0.15511954896110589}

{'Data': 'Train Data', 'Name': 'ExtraTreesRegressor', 'R2_score': 0.9960265302089643, 'Mean_squared_error': 0.0004314232998675398, 'Root_mean_squared_error': 0.020770731808666246, 'Mean_absolute_error': 0.007434562155518487}
{'Data': 'Test Data', 'Name': 'ExtraTreesRegressor', 'R2_score': 0.9468290595402087, 'Mean_squared_error': 0.005754019323661606, 'Root_mean_squared_error': 0.07585525244610031, 'Mean_absolute_error': 0.055874734058306216}

{'Data': 'Train Data', 'Name': 'GradientBoostingRegressor', 'R2_score': 0.8658036483426721, 'Mean_squared_error': 0.014570497803406525, 'Root_mean_squared_error': 0.12070831704322003, 'Mean_absolute_error': 0.09163432682137976}
{'Data': 'Test Data', 'Name': 'GradientBoostingRegressor', 'R2_score': 0.8658367272846111, 'Mean_squared_error': 0.014518796490233432, 'Root_mean_squared_error': 0.12049396868820211, 'Mean_absolute_error': 0.09143635281961868}

{'Data': 'Train Data', 'Name': 'XGBRegressor', 'R2_score': 0.9541519598702629, 'Mean_squared_error': 0.004977995003222205, 'Root_mean_squared_error': 0.07055490771889796, 'Mean_absolute_error': 0.053965258893721425}
{'Data': 'Test Data', 'Name': 'XGBRegressor', 'R2_score': 0.9515654539997473, 'Mean_squared_error': 0.0052414591731546134, 'Root_mean_squared_error': 0.07239792243672889, 'Mean_absolute_error': 0.05543885387355758}

# RandomForestClassifier is good interpretability,
# And it will detect the unseen data for this datas (without overfitting)
# so i select the algorithm

#x,y spliting
x= df_final_5.drop(columns=["resale_price"])
y= df_final_5["resale_price"]

X_train, X_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=42)

model_1= RandomForestRegressor().fit(X_train,y_train)
y_pred= model_1.predict(X_test)

test_mse= mean_squared_error(y_test, y_pred)
test_rmse= np.sqrt(test_mse)
test_mae= mean_absolute_error(y_test, y_pred)
test_r2= r2_score(y_test, y_pred)

metrics_test={"Data": "Test Data",
        "Name":RandomForestRegressor.__name__,
        "R2_score":test_r2,
        "Mean_squared_error":test_mse,
        "Root_mean_squared_error":test_rmse,
        "Mean_absolute_error":test_mae
            }

print(metrics_test)
{'Data': 'Test Data', 'Name': 'RandomForestRegressor', 'R2_score': 0.9550360277761736, 'Mean_squared_error': 0.004865882807548445, 'Root_mean_squared_error': 0.06975588009299606, 'Mean_absolute_error': 0.051622846138960156}
df_final_5.iloc[10456]
year                     2015.000000
town                        4.000000
flat_type                   2.000000
floor_area_sqm             74.000000
flat_model                  8.000000
storey_start                0.011858
storey_end                  1.098612
remaining_lease_year       68.000000
remaining_lease_month       0.000000
lease_commence_date      1985.000000
resale_price               12.815838
Name: 10456, dtype: float64
np.exp(12.815838)
367999.92008841544
user_data = np.array([[2015,4,2,74,8,0.011858,1.098612,68,0,1985]])
y_pred_1 = model_1.predict(user_data)
y_pred_1[0]
12.792003979535888
np.exp(12.792003979535888)
359332.7000997733
# Saving the Model unsing pickle
with open("Resale_Flat_Prices_Model_1.pkl","wb") as f:
  pickle.dump(model_1,f)
import pickle
import numpy as np
with open("Resale_Flat_Prices_Model_1.pkl","rb") as f1:
    regg_model= pickle.load(f1)
user_data = np.array([[2015,8,5,4.955827,3,1.386294,1.791759,73,0,1990]])
y_pred_1 = regg_model.predict(user_data)
y_pred_1[0]
12.313923357750493
np.exp(12.313923357750493)
222776.28881715712
